{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18d1e761",
   "metadata": {},
   "source": [
    "# Experiment on CFGs of new dataset by utilizing 500 nodes to run it on devign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff027c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import json, configs, gc, torch\n",
    "import src.process as process\n",
    "import src.data as data_util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1998cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_x(x, nodes_dim, w2v_size):\n",
    "    new_x = torch.zeros(nodes_dim, w2v_size).float()\n",
    "    new_x[:x.x.size(0), :] = x.x\n",
    "    x.x = new_x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df22ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('new_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c3c7834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of samples in dataset: 12723 \n",
      "\n",
      "\n",
      "\n",
      " **************************************** \n",
      "\n",
      "+------+--------------+\n",
      "|      | Node stats   |\n",
      "+======+==============+\n",
      "| min  | 2            |\n",
      "+------+--------------+\n",
      "| max  | 500          |\n",
      "+------+--------------+\n",
      "| mean | 89.2446      |\n",
      "+------+--------------+\n",
      "| std  | 98.0444      |\n",
      "+------+--------------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+------+--------------+\n",
      "|      | Edge stats   |\n",
      "+======+==============+\n",
      "| min  | 1            |\n",
      "+------+--------------+\n",
      "| max  | 737          |\n",
      "+------+--------------+\n",
      "| mean | 99.3421      |\n",
      "+------+--------------+\n",
      "| std  | 111.119      |\n",
      "+------+--------------+\n",
      "\n",
      "\n",
      "\n",
      "1 = Vulnerable, 0 = Not Vulnerable\n",
      "\n",
      "\n",
      "+------+----------------------+\n",
      "|      | Class 0 Node stats   |\n",
      "+======+======================+\n",
      "| min  | 2                    |\n",
      "+------+----------------------+\n",
      "| max  | 500                  |\n",
      "+------+----------------------+\n",
      "| mean | 92.2276              |\n",
      "+------+----------------------+\n",
      "| std  | 99.0916              |\n",
      "+------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+------+----------------------+\n",
      "|      | Class 0 Edge stats   |\n",
      "+======+======================+\n",
      "| min  | 1                    |\n",
      "+------+----------------------+\n",
      "| max  | 737                  |\n",
      "+------+----------------------+\n",
      "| mean | 102.807              |\n",
      "+------+----------------------+\n",
      "| std  | 112.358              |\n",
      "+------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+------+----------------------+\n",
      "|      | Class 1 Node stats   |\n",
      "+======+======================+\n",
      "| min  | 2                    |\n",
      "+------+----------------------+\n",
      "| max  | 500                  |\n",
      "+------+----------------------+\n",
      "| mean | 86.4439              |\n",
      "+------+----------------------+\n",
      "| std  | 96.975               |\n",
      "+------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+------+----------------------+\n",
      "|      | Class 1 Edge stats   |\n",
      "+======+======================+\n",
      "| min  | 1                    |\n",
      "+------+----------------------+\n",
      "| max  | 733                  |\n",
      "+------+----------------------+\n",
      "| mean | 96.0885              |\n",
      "+------+----------------------+\n",
      "| std  | 109.853              |\n",
      "+------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2v_size  = 200\n",
    "#nodes_dim = int(group.apply(lambda g: nx.number_of_nodes(g.graph),axis=1).describe()['max'])\n",
    "nodes_dim = 500\n",
    "idx = [True if row['input'].x.shape[0]<=nodes_dim else False for index, row in data.iterrows()]\n",
    "data = data[idx]\n",
    "\n",
    "print(\"No of samples in dataset: {} \".format(len(data)))\n",
    "print('\\n'*3,\"*\"*40,'\\n')\n",
    "\n",
    "node_size_group = data.apply(lambda g: g.input.num_nodes,axis=1).describe()[['min', 'max','mean','std']]\n",
    "\n",
    "print(tabulate(node_size_group.to_frame(),\n",
    "               tablefmt=\"grid\", stralign='left', numalign='left',\n",
    "               headers=['Node stats']))\n",
    "\n",
    "\n",
    "print('\\n'*3)\n",
    "\n",
    "edge_size_group = data.apply(lambda g: g.input.num_edges ,axis=1).describe()[['min', 'max','mean','std']]\n",
    "print(tabulate(edge_size_group.to_frame(),\n",
    "                   tablefmt=\"grid\", stralign='left', numalign='left',\n",
    "                   headers=['Edge stats']))\n",
    "\n",
    "print('\\n\\n')\n",
    "print(\"1 = Vulnerable, 0 = Not Vulnerable\")\n",
    "print('\\n')\n",
    "for name, group in data.groupby('target'):\n",
    "    \n",
    "    node_size_group = group.apply(lambda g: g.input.num_nodes, axis=1).describe()[['min', 'max','mean','std']]\n",
    "    edge_size_group = group.apply(lambda g: g.input.num_edges ,axis=1).describe()[['min', 'max','mean','std']]\n",
    "    \n",
    "    print(tabulate(node_size_group.to_frame(),\n",
    "               tablefmt=\"grid\", stralign='left', numalign='left',\n",
    "               headers=['Class {} Node stats'.format(name)]))\n",
    "    \n",
    "    print('\\n'*3)\n",
    "    print(tabulate(edge_size_group.to_frame(),\n",
    "                   tablefmt=\"grid\", stralign='left', numalign='left',\n",
    "                   headers=['Class {} Edge stats'.format(name)]))\n",
    "    print('\\n'*3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fd07cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['input'] = data['input'].apply(lambda x: pad_x(x, nodes_dim, w2v_size) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecc279c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs.json') as f:\n",
    "    json_config = json.load(f)\n",
    "    \n",
    "json_config['devign']['model']['conv_args']['conv1d_1']['in_channels'] = nodes_dim\n",
    "json_config['embed']['nodes_dim']  = nodes_dim\n",
    "json_config['devign']['model']['emb_size']  = w2v_size\n",
    "json_config['embed']['word2vec_args']['size']  = w2v_size\n",
    "\n",
    "with open('configs.json', 'w') as f:\n",
    "    json.dump(json_config,f, indent=4)\n",
    "    \n",
    "PATHS = configs.Paths()\n",
    "FILES = configs.Files()\n",
    "DEVICE = FILES.get_device()\n",
    "\n",
    "context = configs.Process()\n",
    "devign = configs.Devign()\n",
    "model_path = PATHS.model + FILES.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b04f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new fc1 2000 new fc2 size 1000\n",
      "The model has 560,272 trainable parameters\n",
      "Splitting Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ammar/vuln_code/vuln_env/lib/python3.9/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1; - Train Loss: 0.3661; Acc: 0.1813; - Validation Loss: 3.8542; Acc: 0.1497; - Time: 529.6525275707245\n",
      "\n",
      "Epoch 2; - Train Loss: 0.452; Acc: 0.1724; - Validation Loss: 2.9757; Acc: 0.1557; - Time: 773.9536793231964\n",
      "\n",
      "Epoch 3; - Train Loss: 0.4939; Acc: 0.1741; - Validation Loss: 9.9673; Acc: 0.1796; - Time: 1018.9731566905975\n",
      "\n",
      "Epoch 4; - Train Loss: 0.4721; Acc: 0.1975; - Validation Loss: 18.1449; Acc: 0.2754; - Time: 1265.5171356201172\n",
      "\n",
      "Epoch 5; - Train Loss: 0.6153; Acc: 0.1679; - Validation Loss: 2.9816; Acc: 0.1497; - Time: 1511.0969188213348\n",
      "\n",
      "Epoch 6; - Train Loss: 0.4408; Acc: 0.1885; - Validation Loss: 15.5872; Acc: 0.2575; - Time: 1756.733506679535\n",
      "\n",
      "Epoch 7; - Train Loss: 0.5048; Acc: 0.1616; - Validation Loss: 2.9873; Acc: 0.1437; - Time: 2002.692902803421\n",
      "\n",
      "Epoch 8; - Train Loss: 0.4175; Acc: 0.2092; - Validation Loss: 41.5218; Acc: 0.4618; - Time: 2301.779297351837\n",
      "\n",
      "Epoch 9; - Train Loss: 2.5825; Acc: 0.1921; - Validation Loss: 2.986; Acc: 0.1557; - Time: 2853.7011320590973\n"
     ]
    }
   ],
   "source": [
    "model_path = PATHS.model + FILES.model\n",
    "model = process.Devign(path=model_path, device=DEVICE, model=devign.model, learning_rate=devign.learning_rate,\n",
    "                       weight_decay=devign.weight_decay,\n",
    "                       loss_lambda=devign.loss_lambda)\n",
    "train = process.Train(model, context.epochs)\n",
    "input_dataset = data[[\"input\", \"target\"]]\n",
    "# split the dataset and pass to DataLoader with batch size\n",
    "train_loader, val_loader, test_loader = list(\n",
    "    map(lambda x: x.get_loader(context.batch_size, shuffle=context.shuffle),\n",
    "        data_util.train_val_test_split(input_dataset, shuffle=context.shuffle)))\n",
    "train_loader_step = process.LoaderStep(\"Train\", train_loader, DEVICE)\n",
    "val_loader_step = process.LoaderStep(\"Validation\", val_loader, DEVICE)\n",
    "train(train_loader_step, val_loader_step)\n",
    "print('Finish Training for {}'.format(name))\n",
    "spinner.stop()\n",
    "spinner.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f949f31a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1102229/600581484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/vuln_code/vuln_env/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554329f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[row['input'].x for index, row in data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e5b247e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.55"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2853/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "453ef735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12723"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e1e0f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9422350588758054"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12723/13503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cae8460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-780"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12723-13503"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2654f70-196e-4e8d-81c8-a3ff1db3311e",
   "metadata": {},
   "source": [
    "## Code for GIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948f22a-f6de-4b35-ace6-4571824c54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodesEmbedding:\n",
    "    def __init__(self, nodes_dim: int, w2v_keyed_vectors: Word2VecKeyedVectors):\n",
    "        self.w2v_keyed_vectors = w2v_keyed_vectors\n",
    "        self.kv_size = w2v_keyed_vectors.vector_size\n",
    "        self.nodes_dim = nodes_dim\n",
    "\n",
    "        assert self.nodes_dim >= 0\n",
    "\n",
    "        # Buffer for embeddings with padding\n",
    "        self.target = torch.zeros(self.nodes_dim, self.kv_size).float()\n",
    "\n",
    "    def __call__(self, nodes):\n",
    "        embedded_nodes = self.embed_nodes(nodes)\n",
    "\n",
    "        nodes_tensor = torch.from_numpy(embedded_nodes).float()\n",
    "\n",
    "        self.target[:nodes_tensor.size(0), :] = nodes_tensor\n",
    "\n",
    "        return self.target\n",
    "\n",
    "    def embed_nodes(self, G):\n",
    "        embeddings = []\n",
    "\n",
    "        for (n,d) in G.nodes(data=True):\n",
    "            # Get node's code\n",
    "            node_code = d\n",
    "            # Tokenize the code\n",
    "            tokenized_code = tokenizer(\"\".join(d.values()))\n",
    "            if not tokenized_code:\n",
    "                # print(f\"Dropped node {node}: tokenized code is empty.\")\n",
    "                msg = f\"Empty TOKENIZED from node CODE {node_code}\"\n",
    "                print(msg)\n",
    "            # Get each token's learned embedding vector\n",
    "            vectorized_code = np.array(self.get_vectors(tokenized_code))\n",
    "            # The node's source embedding is the average of it's embedded tokens\n",
    "            source_embedding = np.mean(vectorized_code, 0)\n",
    "            # The node representation is the concatenation of label and source embeddings\n",
    "            #embedding = np.concatenate((np.array([node.type]), source_embedding), axis=0)\n",
    "            embeddings.append(source_embedding)\n",
    "        # print(node.label, node.properties.properties.get(\"METHOD_FULL_NAME\"))\n",
    "        \n",
    "        return np.array(embeddings)\n",
    "\n",
    "    # fromTokenToVectors\n",
    "    def get_vectors(self, tokenized_code):\n",
    "        vectors = []\n",
    "        for token in tokenized_code:\n",
    "            if token in self.w2v_keyed_vectors.key_to_index:\n",
    "                vectors.append(self.w2v_keyed_vectors[token])\n",
    "            else:\n",
    "                # print(node.label, token, node.get_code(), tokenized_code)\n",
    "                vectors.append(np.zeros(self.kv_size))\n",
    "        return vectors\n",
    "\n",
    "\n",
    "\n",
    "def nodes_to_input(G, target, nodes_dim, keyed_vectors):\n",
    "    nodes_embedding = NodesEmbedding(nodes_dim, keyed_vectors)\n",
    "    edge_index, edge_attr = convert.from_scipy_sparse_matrix(nx.adjacency_matrix(G))\n",
    "    label = torch.tensor([target]).float()\n",
    "\n",
    "    return Data(x=nodes_embedding(G), edge_index=edge_index, edge_attr=edge_attr ,y=label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "020d8ce6-b787-44ac-8aed-5020b6d8d62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file/pandas\n"
     ]
    }
   ],
   "source": [
    "print('Writing to file/pandas')\n",
    "pd.to_pickle(data[['graph','target']], 'new_data_nx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "305013fc-801c-44e6-ae9c-d053047de55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"dataset1/positive_cfg total\": 10786,\n",
      "    \"dataset1/positive_cfg removed\": 3360,\n",
      "    \"dataset1/positive_cfg used\": 7426,\n",
      "    \"dataset1/negative_cfg total\": 10786,\n",
      "    \"dataset1/negative_cfg removed\": 2850,\n",
      "    \"dataset1/negative_cfg used\": 7936\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(dict_e, indent=4))\n",
    "data = pd.DataFrame(pd_list)\n",
    "data = data[['target', 'project', 'graph','func_code','index']]\n",
    "data = data.rename(columns={'func_code': 'func'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba800553-a634-47c7-a6bd-de49f7c9cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = data.graph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "065b3510-aa92-4670-9750-d7032a2547e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'AdjacencyView' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25958/1891971723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'AdjacencyView' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "for d, n in c.nodes(data=True):\n",
    "    c[d]['x'] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e1c540-e893-416e-9de0-640c65a00f7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25958/1076518229.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No of samples in dataset: {} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnode_size_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"No of samples in dataset: {} \".format(len(data)))\n",
    "print('\\n'*3,\"*\"*40,'\\n')\n",
    "\n",
    "node_size_group = data.apply(lambda g: nx.number_of_nodes(g.graph),axis=1).describe()[['min', 'max','mean','std']]\n",
    "\n",
    "print(tabulate(node_size_group.to_frame(),\n",
    "               tablefmt=\"grid\", stralign='left', numalign='left',\n",
    "               headers=['Node stats']))\n",
    "\n",
    "\n",
    "print('\\n'*3)\n",
    "print(\"1 = Vulnerable, 0 = Not Vulnerable\")\n",
    "edge_size_group = data.apply(lambda g: nx.number_of_edges(g.graph),axis=1).describe()[['min', 'max','mean','std']]\n",
    "print(tabulate(edge_size_group.to_frame(),\n",
    "                   tablefmt=\"grid\", stralign='left', numalign='left',\n",
    "                   headers=['Edge stats']))\n",
    "\n",
    "for name in group, data.groupby('target'):\n",
    "    print(tabulate(node_size_group.to_frame(),\n",
    "               tablefmt=\"grid\", stralign='left', numalign='left',\n",
    "               headers=['Class {} Node stats'.format(name)]))\n",
    "    \n",
    "    edge_size_group = data.apply(lambda g: nx.number_of_edges(g.graph),axis=1).describe()[['min', 'max','mean','std']]\n",
    "    print(tabulate(edge_size_group.to_frame(),\n",
    "                   tablefmt=\"grid\", stralign='left', numalign='left',\n",
    "                   headers=['Class {} Edge stats'.format(name)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32cb1556-c65d-4673-99b5-dc39040b6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('new_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c0cc51a-db72-4eb6-b966-ee84b30d8f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"input\"] = data.apply(lambda row: nodes_to_input(row.graph, row.target, nx.number_of_nodes(row.graph),\n",
    "                                                                                    w2vmodel.wv), axis=1)\n",
    "print('Writing to file/pandas')\n",
    "pd.to_pickle(data[['input','target']], 'new_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a9c1dd-7076-469b-b371-8f8ecebd3ef6",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40909/3460235785.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'new_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/vuln_code/vuln_env/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# letting pickle write directly to the buffer is more memory-efficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             pickle.dump(\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;31m# error: Argument 2 to \"dump\" has incompatible type \"Union[IO[Any],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# RawIOBase, BufferedIOBase, TextIOBase, TextIOWrapper, mmap]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "pd.to_pickle(data[['input','target']], 'new_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ca82fb-4f77-4860-ba80-abc17cf01476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|      | Edge stats   |\n",
      "+======+==============+\n",
      "| min  | 1            |\n",
      "+------+--------------+\n",
      "| max  | 11993        |\n",
      "+------+--------------+\n",
      "| mean | 163.733      |\n",
      "+------+--------------+\n",
      "| std  | 352.179      |\n",
      "+------+--------------+\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(pd_list)\n",
    "edge_size_group = data.apply(lambda g: nx.number_of_edges(g.graph),axis=1).describe()[['min', 'max','mean','std']]\n",
    "print(tabulate(edge_size_group.to_frame(),\n",
    "                   tablefmt=\"grid\", stralign='left', numalign='left',\n",
    "                   headers=['Edge stats']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cb75296-a679-48d3-b839-4f46f729e61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>project</th>\n",
       "      <th>func_code</th>\n",
       "      <th>graph</th>\n",
       "      <th>is_connected</th>\n",
       "      <th>dot_string</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351</td>\n",
       "      <td>positive_cfg</td>\n",
       "      <td>static int vmci_transport_dgram_dequeue(struct...</td>\n",
       "      <td>(1000117, 1000119, 1000123, 1000124, 1000127, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>digraph vmci_transport_dgram_dequeue {\\n\"10001...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2623</td>\n",
       "      <td>positive_cfg</td>\n",
       "      <td>static const char *parse_array( cJSON *item, c...</td>\n",
       "      <td>(1000113, 1000114, 1000118, 1000121, 1000123, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>digraph parse_array {\\n\"1000113\" [label = \"(&lt;o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2903</td>\n",
       "      <td>positive_cfg</td>\n",
       "      <td>asmlinkage int arm_syscall(int no, struct pt_r...</td>\n",
       "      <td>(1000113, 1000115, 1000118, 1000119, 1000122, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>digraph arm_syscall {\\n\"1000113\" [label = \"(&lt;o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5323</td>\n",
       "      <td>positive_cfg</td>\n",
       "      <td>static ssize_t aio_run_iocb(struct kiocb *req,...</td>\n",
       "      <td>(1000111, 1000113, 1000115, 1000124, 1000133, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>digraph aio_run_iocb {\\n\"1000111\" [label = \"(&lt;...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1469</td>\n",
       "      <td>positive_cfg</td>\n",
       "      <td>cib_remote_connection_destroy(gpointer user_d...</td>\n",
       "      <td>(1000104, 1000108, 1000112, 1000113, 1000115, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>digraph cib_remote_connection_destroy {\\n\"1000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       project                                          func_code  \\\n",
       "0   1351  positive_cfg  static int vmci_transport_dgram_dequeue(struct...   \n",
       "1   2623  positive_cfg  static const char *parse_array( cJSON *item, c...   \n",
       "2   2903  positive_cfg  asmlinkage int arm_syscall(int no, struct pt_r...   \n",
       "3   5323  positive_cfg  static ssize_t aio_run_iocb(struct kiocb *req,...   \n",
       "4   1469  positive_cfg   cib_remote_connection_destroy(gpointer user_d...   \n",
       "\n",
       "                                               graph  is_connected  \\\n",
       "0  (1000117, 1000119, 1000123, 1000124, 1000127, ...          True   \n",
       "1  (1000113, 1000114, 1000118, 1000121, 1000123, ...          True   \n",
       "2  (1000113, 1000115, 1000118, 1000119, 1000122, ...          True   \n",
       "3  (1000111, 1000113, 1000115, 1000124, 1000133, ...          True   \n",
       "4  (1000104, 1000108, 1000112, 1000113, 1000115, ...          True   \n",
       "\n",
       "                                          dot_string  target  \n",
       "0  digraph vmci_transport_dgram_dequeue {\\n\"10001...       1  \n",
       "1  digraph parse_array {\\n\"1000113\" [label = \"(<o...       1  \n",
       "2  digraph arm_syscall {\\n\"1000113\" [label = \"(<o...       1  \n",
       "3  digraph aio_run_iocb {\\n\"1000111\" [label = \"(<...       1  \n",
       "4  digraph cib_remote_connection_destroy {\\n\"1000...       1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aab4b69a-63b0-41ee-915b-1ec89614442c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[172, 200], edge_index=[2, 216], edge_attr=[216], y=[1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[8].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ff9c0-3236-47d8-ac56-2df1d5873e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
